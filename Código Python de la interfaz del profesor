import numpy as np
import pandas as pd
import tkinter as tk
from tkinter import filedialog, messagebox, simpledialog, ttk
from tensorflow.keras.models import load_model
from tensorflow.keras.losses import MeanSquaredError
import openai
import requests

class PredictorChatbotApp:
    def __init__(self, root):
        self.root = root
        self.root.title("Herramienta de Estilos de Aprendizaje y Chatbot")
        self.root.geometry("600x500")  # Increased window size for better layout
        self.root.configure(bg="#E3F2FD")  # Light blue background

        style = ttk.Style()
        style.theme_use("clam")  # Use 'clam' theme for a modern look
        style.configure("TButton", font=("Arial", 12), padding=10, background="#1E88E5", foreground="white")
        style.configure("TLabel", font=("Arial", 12), background="#E3F2FD", foreground="#0D47A1")
        style.configure("TFrame", background="#E3F2FD")
        style.configure("TCombobox", font=("Arial", 12), padding=5)

        api_frame = ttk.Frame(self.root, padding="10")
        api_frame.pack(fill='x', pady=(10, 0))
        api_label = ttk.Label(api_frame, text="Seleccionar API para Chat:")
        api_label.pack(side='left', padx=10)
        self.api_option = tk.StringVar(value="OpenAI")
        self.api_dropdown = ttk.Combobox(api_frame, textvariable=self.api_option, values=[
            "OpenAI", "Hugging Face", "GPT-J", "Cohere", "TextSynth", "LLaMA 3", "OLMo"
        ])
        self.api_dropdown.pack(side='left', padx=10)

        data_frame = ttk.Frame(self.root, padding="10")
        data_frame.pack(fill='x', pady=(10, 0))
        upload_button = ttk.Button(data_frame, text="Cargar Datos para Predicción", command=self.upload_data)
        upload_button.pack(pady=5)

        analyze_frame = ttk.Frame(self.root, padding="10")
        analyze_frame.pack(fill='x', pady=(10, 0))
        analyze_styles_button = ttk.Button(analyze_frame, text="Cargar y Analizar Estilos de Aprendizaje", command=self.upload_and_analyze)
        analyze_styles_button.pack(pady=5)

        chat_frame = ttk.Frame(self.root, padding="10")
        chat_frame.pack(fill='x', pady=(10, 0))
        chat_button = ttk.Button(chat_frame, text="Preguntar a GPT", command=self.ask_gpt)
        chat_button.pack(pady=5)

        self.model = self.load_lstm_model()

        # Set your OpenAI API key here (ensure you keep this key secure)
        openai.api_key = 'Entrar codigo de API'  

    def load_lstm_model(self):
        # Update the path to your LSTM model
        model_path = r"C:\Users\X\OneDrive\software\my_lstm_model.keras"
        return load_model(model_path, custom_objects={'mse': MeanSquaredError()})

    def upload_data(self):
        file_path = filedialog.askopenfilename(filetypes=[("Excel files", "*.xlsx;*.xls")])
        if file_path:
            try:
                data = pd.read_excel(file_path)
                output_data = []

                for index, row in data.iterrows():
                    X = np.array(row[2:7], dtype=np.float32).reshape((1, 5, 1))  # Assuming data starts from column C to G
                    prediction = self.model.predict(X)[0]
                    output_data.append([row[0], row[1]] + prediction.tolist())  # Convert numpy array to list

                output_df = pd.DataFrame(output_data, columns=["Número de Estudiante", "Estilo de Aprendizaje"] + [f"Semana {i}" for i in range(6, 17)])
                save_path = filedialog.asksaveasfilename(defaultextension=".xlsx", filetypes=[("Excel files", "*.xlsx;*.xls")], initialfile='predicciones.xlsx')
                if save_path:
                    output_df.to_excel(save_path, index=False)
                    messagebox.showinfo("Éxito", "Predicciones guardadas en " + save_path)
            except Exception as e:
                messagebox.showerror("Error", f"Ocurrió un error durante la predicción: {str(e)}")

    def upload_and_analyze(self):
        file_path = filedialog.askopenfilename(filetypes=[("Excel files", "*.xlsx;*.xls")])
        if file_path:
            try:
                # Load data, ensuring the correct decimal handling
                data = pd.read_excel(file_path, decimal=',') 
                results = self.analyze_styles(data)
                # Display the results
                info_message = "\n".join([f"{dim}: {res['High']}, {res['Low']}" for dim, res in results.items()])
                messagebox.showinfo("Porcentajes de Estilos de Aprendizaje", info_message)
            except Exception as e:
                messagebox.showerror("Error", f"Ocurrió un error al procesar el archivo: {str(e)}")

    def analyze_styles(self, data):
        thresholds = {
            'AR': (0.6, 'Activo', 0.4, 'Reflexivo'),
            'SI': (0.6, 'Secuencial', 0.4, 'Intuitivo'),
            'VB': (0.6, 'Visual', 0.4, 'Verbal'),
            'SG': (0.6, 'Secuencial', 0.4, 'Global')
        }
        results = {dimension: {'High': 0, 'Low': 0} for dimension in thresholds}
        for dimension, (high_thresh, high_label, low_thresh, low_label) in thresholds.items():
            dimension_data = data[data['Learning Dimension'] == dimension]['Week 1']
            high_count = (dimension_data > high_thresh).sum()
            low_count = (dimension_data < low_thresh).sum()
            total_count = dimension_data.count()
            if total_count > 0:
                results[dimension]['High'] = f"{high_count / total_count * 100:.2f}% {high_label}"
                results[dimension]['Low'] = f"{low_count / total_count * 100:.2f}% {low_label}"
        return results

    def ask_gpt(self):
        question = simpledialog.askstring("Pregunta", "¿Qué quieres preguntar?")
        if question:
            api_choice = self.api_option.get()
            try:
                if api_choice == "OpenAI":
                    response = openai.ChatCompletion.create(
                        model="gpt-3.5-turbo",
                        messages=[{"role": "system", "content": "You are helpful."}, {"role": "user", "content": question}]
                    )
                    response_text = response.choices[0].message['content']
                elif api_choice == "Hugging Face":
                    response_text = self.ask_hugging_face(question)
                elif api_choice == "GPT-J":
                    response_text = self.ask_gpt_j(question)
                elif api_choice == "Cohere":
                    response_text = self.ask_cohere(question)
                elif api_choice == "TextSynth":
                    response_text = self.ask_textsynth(question)
                elif api_choice == "LLaMA 3":
                    response_text = self.ask_llama3(question)
                elif api_choice == "OLMo":
                    response_text = self.ask_olmo(question)
                else:
                    response_text = "API no soportada."
                messagebox.showinfo("Respuesta", response_text)
            except Exception as e:
                messagebox.showerror("Error", f"No se pudo obtener respuesta: {str(e)}")

if __name__ == '__main__':
    root = tk.Tk()
    app = PredictorChatbotApp(root)
    root.mainloop()
